from bs4 import BeautifulSoup
import re
import os
import requests


def get_problem_info(workbook_url):
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/124.0.0.0 Safari/537.36"
        )
    }
    print(f"ğŸŒ ìš”ì²­ ì¤‘: {workbook_url}")
    response = requests.get(workbook_url, headers=headers)
    print(f"ğŸ“¥ ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ: ìƒíƒœ ì½”ë“œ {response.status_code}")

    soup = BeautifulSoup(response.text, "html.parser")
    problem_map = {}

    for a_tag in soup.select('a[href^="/problem/"]'):
        href = a_tag.get("href")
        prob_id = href.split("/")[-1]
        prob_title = a_tag.text.strip()
        norm_title = re.sub(r"[^ê°€-í£a-zA-Z0-9]", "", prob_title)

        if prob_id.isdigit():
            problem_map[norm_title] = prob_id
            print(f'  ğŸ” {norm_title} â† "{prob_title}" â†’ {prob_id}')

    print(f"\nğŸ“‹ ì¶”ì¶œëœ ë¬¸ì œ ìˆ˜: {len(problem_map)}ê°œ")
    return problem_map


# íŒŒì¼ ë¦¬ë„¤ì´ë°
def rename_files(folder_path, problem_map):
    renamed = 0
    files = os.listdir(folder_path)
    print(f"ğŸ“ ë””ë ‰í† ë¦¬ ëª©ë¡: {files}")
    for fname in files:
        ext = os.path.splitext(fname)[1]
        if ext not in [".cpp", ".py"]:
            continue
        base = os.path.splitext(fname)[0]
        normalized = re.sub(r"[^ê°€-í£a-zA-Z0-9]", "", base)
        print(f"ğŸ” íŒŒì¼ ì²´í¬: {fname} â†’ ì •ê·œí™”: {normalized}")
        if normalized in problem_map:
            prob_id = problem_map[normalized]
            new_name = f"{prob_id}{ext}"
            old_path = os.path.join(folder_path, fname)
            new_path = os.path.join(folder_path, new_name)
            if old_path != new_path:
                os.rename(old_path, new_path)
                print(f"âœ”ï¸ {fname} â†’ {new_name}")
                renamed += 1
        else:
            print(f"âš ï¸ ë§¤í•‘ ì‹¤íŒ¨: {normalized}ëŠ” ë¬¸ì œì§‘ì— ì—†ìŒ")
    return renamed


# links.txtì—ì„œ ë‹¨ì›ë³„ ì½”ë“œì™€ URL ì½ê¸°
def parse_links():
    with open("links.txt", encoding="utf-8") as f:
        lines = [line.strip().split(",") for line in f if line.strip()]
    print(f"ğŸ§¾ links.txt ë‚´ìš©:\n{lines}")
    return [
        (code.strip(), url.strip()) for code, _, url in lines if url.startswith("http")
    ]


# ì „ì²´ ìë™ ì²˜ë¦¬
def auto_rename_all():
    print("ğŸ“‚ links.txtì—ì„œ ë‹¨ì›ë³„ ë¬¸ì œì§‘ ì½ëŠ” ì¤‘...")
    links = parse_links()
    total = 0
    for code, url in links:
        folder = f"../{code}/"
        if not os.path.isdir(folder):
            print(f"âŒ í´ë” ì—†ìŒ: {folder}")
            continue
        print(f"\nğŸ“¥ {code} - ë¬¸ì œì§‘ URL: {url}")
        try:
            problem_map = get_problem_info(url)
        except Exception as e:
            print(f"âŒ ë¬¸ì œì§‘ íŒŒì‹± ì‹¤íŒ¨: {e}")
            continue
        print(f"ğŸ” íŒŒì¼ ë¦¬ë„¤ì´ë° ì¤‘ in {folder} ...")
        try:
            count = rename_files(folder, problem_map)
            print(f"âœ… {count}ê°œ íŒŒì¼ ë³€ê²½ ì™„ë£Œ")
            total += count
        except Exception as e:
            print(f"âŒ ë¦¬ë„¤ì´ë° ì˜¤ë¥˜: {e}")
    print(f"\nğŸ‰ ì „ì²´ ì™„ë£Œ! ì´ {total}ê°œ íŒŒì¼ ë³€ê²½ë¨.")


if __name__ == "__main__":
    auto_rename_all()
